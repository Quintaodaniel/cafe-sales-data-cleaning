{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dde3378",
   "metadata": {},
   "source": [
    "# Data Cleaning Project: Cafe Sales\n",
    "\n",
    "**Objective:** To perform a complete data cleaning process.\n",
    "\n",
    "**Index:**\n",
    "* Introduction: Import libraries and load the \"dirty\" .csv file;\n",
    "* Step 1: Initial dataset diagnosis;\n",
    "* Step 2: Adjusting Data Types;\n",
    "* Step 3: Standardizing errors;\n",
    "* Step 4: Correcting errors;\n",
    "* Step 5: Checking for Duplicated Data;\n",
    "* Step 6: Final Validation;\n",
    "* Step 7: Save a new clean .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46f009ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_4977031</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_4271903</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_7034554</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_3160411</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID    Item Quantity Price Per Unit Total Spent  Payment Method  \\\n",
       "0    TXN_1961373  Coffee        2            2.0         4.0     Credit Card   \n",
       "1    TXN_4977031    Cake        4            3.0        12.0            Cash   \n",
       "2    TXN_4271903  Cookie        4            1.0       ERROR     Credit Card   \n",
       "3    TXN_7034554   Salad        2            5.0        10.0         UNKNOWN   \n",
       "4    TXN_3160411  Coffee        2            2.0         4.0  Digital Wallet   \n",
       "\n",
       "   Location Transaction Date  \n",
       "0  Takeaway       2023-09-08  \n",
       "1  In-store       2023-05-16  \n",
       "2  In-store       2023-07-19  \n",
       "3   UNKNOWN       2023-04-27  \n",
       "4  In-store       2023-06-11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Introduction\n",
    "\n",
    "# Import Pandas and Numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the csv file\n",
    "file_path = \"../data/raw/dirty_cafe_sales.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"File loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found!\")\n",
    "\n",
    "# Display the first 5 rows\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472db9bb",
   "metadata": {},
   "source": [
    "## Step 1: Initial Dataset Diagnosis\n",
    "\n",
    "Before we change anything, let's first perform a complete \"checkup\" of our DataFrame to understand where the problems are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac931a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== GENERAL INFORMATION ==================\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Transaction ID    10000 non-null  object\n",
      " 1   Item              9667 non-null   object\n",
      " 2   Quantity          9862 non-null   object\n",
      " 3   Price Per Unit    9821 non-null   object\n",
      " 4   Total Spent       9827 non-null   object\n",
      " 5   Payment Method    7421 non-null   object\n",
      " 6   Location          6735 non-null   object\n",
      " 7   Transaction Date  9841 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 625.1+ KB\n",
      "\n",
      "========== COUNT OF MISSING (NULL) VALUES ==========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transaction ID         0\n",
       "Item                 333\n",
       "Quantity             138\n",
       "Price Per Unit       179\n",
       "Total Spent          173\n",
       "Payment Method      2579\n",
       "Location            3265\n",
       "Transaction Date     159\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Technical summary: data types and non-null count\n",
    "print(\"================== GENERAL INFORMATION ==================\\n\")\n",
    "df.info()\n",
    "\n",
    "# Count of missing (null) values in each column\n",
    "print(\"\\n========== COUNT OF MISSING (NULL) VALUES ==========\")\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128cecef",
   "metadata": {},
   "source": [
    "### Issues:\n",
    "\n",
    "**Missing Values:** The presence of null values is noted in all columns (except for 'Transaction ID'), in addition to errors masked as 'UNKNOWN' and 'ERROR'.\n",
    "\n",
    "**Column Types:** The 'Quantity', 'Price Per Unit', 'Total Spent', and 'Transaction Date' columns are of the object (String) type.\n",
    "\n",
    "By converting them to the correct types (Float and DateTime, respectively), non-obvious errors like the ones mentioned above will automatically become null, which will help us!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6370ff49",
   "metadata": {},
   "source": [
    "## Step 2: Adjusting Data Types\n",
    "\n",
    "As mentioned above, converting the columns to their respective types will be a powerful and beneficial move for when we actually clean the data.\n",
    "\n",
    "Here, we will convert the 'Quantity', 'Price Per Unit', and 'Total Spent' columns to float, and the 'Transaction Date' column to DateTime.\n",
    "\n",
    "Since we will actually be altering our DataFrame here, we will copy it to 'df_clean' so as not to modify our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf85cefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column types changed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a copy to work safely\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Correcting numeric columns\n",
    "numeric_columns = ['Price Per Unit', 'Quantity', 'Total Spent']\n",
    "\n",
    "for column in numeric_columns:\n",
    "    df_clean[column] = pd.to_numeric(df_clean[column], errors='coerce')\n",
    "\n",
    "# Correcting Date column\n",
    "df_clean['Transaction Date'] = pd.to_datetime(df_clean['Transaction Date'], errors='coerce')\n",
    "\n",
    "print(\"Column types changed!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f2677b",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Notice that we have now uncovered more errors in the columns that had the wrong data types. Take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80a6e20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== BEFORE ==========\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Transaction ID    10000 non-null  object\n",
      " 1   Item              9667 non-null   object\n",
      " 2   Quantity          9862 non-null   object\n",
      " 3   Price Per Unit    9821 non-null   object\n",
      " 4   Total Spent       9827 non-null   object\n",
      " 5   Payment Method    7421 non-null   object\n",
      " 6   Location          6735 non-null   object\n",
      " 7   Transaction Date  9841 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 625.1+ KB\n",
      "\n",
      "========== AFTER ==========\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Transaction ID    10000 non-null  object        \n",
      " 1   Item              9667 non-null   object        \n",
      " 2   Quantity          9521 non-null   float64       \n",
      " 3   Price Per Unit    9467 non-null   float64       \n",
      " 4   Total Spent       9498 non-null   float64       \n",
      " 5   Payment Method    7421 non-null   object        \n",
      " 6   Location          6735 non-null   object        \n",
      " 7   Transaction Date  9540 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(3), object(4)\n",
      "memory usage: 625.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Info before the transformation and the non-null count:\n",
    "print(\"\\n========== BEFORE ==========\\n\")\n",
    "df.info()\n",
    "\n",
    "# Info after the transformation and the non-null count:\n",
    "print(\"\\n========== AFTER ==========\\n\")\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970cfa2",
   "metadata": {},
   "source": [
    "## Step 3: Standardizing Errors\n",
    "\n",
    "Standardizing errors is crucial to ensure the **consistency and accuracy** of your data, which leads to more reliable analyses. This **facilitates the automation** of cleaning processes and allows the team to focus more time on analysis rather than on manual correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90e5439c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values have been standardized!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_4977031</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_4271903</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_7034554</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_3160411</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TXN_2602893</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TXN_4433211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-10-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID      Item  Quantity  Price Per Unit  Total Spent  \\\n",
       "0    TXN_1961373    Coffee       2.0             2.0          4.0   \n",
       "1    TXN_4977031      Cake       4.0             3.0         12.0   \n",
       "2    TXN_4271903    Cookie       4.0             1.0          NaN   \n",
       "3    TXN_7034554     Salad       2.0             5.0         10.0   \n",
       "4    TXN_3160411    Coffee       2.0             2.0          4.0   \n",
       "5    TXN_2602893  Smoothie       5.0             4.0         20.0   \n",
       "6    TXN_4433211       NaN       3.0             3.0          9.0   \n",
       "\n",
       "   Payment Method  Location Transaction Date  \n",
       "0     Credit Card  Takeaway       2023-09-08  \n",
       "1            Cash  In-store       2023-05-16  \n",
       "2     Credit Card  In-store       2023-07-19  \n",
       "3             NaN       NaN       2023-04-27  \n",
       "4  Digital Wallet  In-store       2023-06-11  \n",
       "5     Credit Card       NaN       2023-03-31  \n",
       "6             NaN  Takeaway       2023-10-06  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values_to_treat_as_null = ['', ' ', 'UNKNOWN', 'ERROR']\n",
    "\n",
    "# Standardizing all types of null values\n",
    "df_clean.replace(values_to_treat_as_null, np.nan, inplace=True)\n",
    "\n",
    "print(\"Missing values have been standardized!\")\n",
    "\n",
    "display(df_clean.head(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9bd88d",
   "metadata": {},
   "source": [
    "## Step 4: Correcting Errors\n",
    "\n",
    "Before we handle the null values, we need to classify the columns into levels of relevance for our analysis.\n",
    "\n",
    "**Essential Columns:** If a value is missing in any of these columns, the entire row becomes practically useless for most business analyses.\n",
    "\n",
    "**Important Columns:** These columns are extremely important, but in some scenarios, their absence can be worked around (through filling/imputation) without completely invalidating the sales record.\n",
    "\n",
    "**Contextual Columns:** These columns add valuable detail and context, but their absence does not invalidate the transaction record in any way.\n",
    "\n",
    "**Derived Columns:** These are columns that are a function of others.\n",
    "\n",
    "The relevance level of a column defines how \"Null\" values will be handled. For Essential columns: the entire row will be removed. For Important and Contextual columns: they will be filled with the Mode. For Derived columns: a validation will be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5fa458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls in column 'Location' filled with the mode: 'In-store'\n",
      "Nulls in column 'Payment Method' filled with the mode: 'Digital Wallet'\n",
      "\n",
      "'Total Spent' column validated, rebuilt, and consistent!\n",
      "Checking if nulls still exist in 'Total Spent' (there shouldn't be any): 0\n"
     ]
    }
   ],
   "source": [
    "# Classifying the Columns\n",
    "essential_columns = ['Transaction Date', 'Price Per Unit', 'Quantity', 'Item']\n",
    "important_columns = ['Transaction ID'] # Since there are no nulls in this column, I won't use it\n",
    "contextual_columns = ['Location', 'Payment Method']\n",
    "\n",
    "# ========== Handling Nulls in Essential Columns ==========\n",
    "# Removing all rows that have null values in the essential columns\n",
    "df_clean.dropna(subset=essential_columns, inplace=True)\n",
    "\n",
    "# ========== Handling Nulls in Contextual Columns ==========\n",
    "# Loop to handle each column in the list\n",
    "for column in contextual_columns:\n",
    "    # Calculate the mode (the most frequent value)\n",
    "    # We use .mode()[0] because .mode() returns a Series (in case of a tie for the mode),\n",
    "    # and we want to get only the first value.\n",
    "    mode = df_clean[column].mode()[0]\n",
    "\n",
    "    # Fill the null values (NaN) with the mode\n",
    "    df_clean[column] = df_clean[column].fillna(mode)\n",
    "\n",
    "    print(f\"Nulls in column '{column}' filled with the mode: '{mode}'\")\n",
    "\n",
    "# ========== Handling the 'Total Spent' column ==========\n",
    "# Prerequisite: The 'Quantity' and 'Price Per Unit' columns must already be clean\n",
    "# (types corrected, nulls handled, etc.)\n",
    "\n",
    "# 1. Calculate a new 'calculated_total' column for verification\n",
    "#    This allows us to compare with the original 'Total Spent' column.\n",
    "df_clean['calculated_total'] = df_clean['Quantity'] * df_clean['Price Per Unit']\n",
    "\n",
    "# 2. Replace the original column with the calculated one\n",
    "df_clean['Total Spent'] = df_clean['calculated_total']\n",
    "\n",
    "# 3. Final Cleanup: Remove the temporary columns we created\n",
    "df_clean.drop(columns=['calculated_total'], inplace=True)\n",
    "\n",
    "print(\"\\n'Total Spent' column validated, rebuilt, and consistent!\")\n",
    "\n",
    "print(f\"Checking if nulls still exist in 'Total Spent' (there shouldn't be any): {df_clean['Total Spent'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c55def4",
   "metadata": {},
   "source": [
    "## Step 5: Checking for Duplicate Data\n",
    "\n",
    "Now that there are no longer any null values or inconsistencies, we can check for duplicate rows. If there are any, we will need to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e648c465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============== COUNTING DUPLICATE ROWS ==============\n",
      "The dataset has 0 duplicate rows.\n"
     ]
    }
   ],
   "source": [
    "# Counting duplicate rows\n",
    "print(\"\\n============== COUNTING DUPLICATE ROWS ==============\")\n",
    "num_duplicates = df.duplicated().sum()\n",
    "print(f\"The dataset has {num_duplicates} duplicate rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d9dc9",
   "metadata": {},
   "source": [
    "## Step 6: Final Validation\n",
    "\n",
    "Since there are no duplicate rows, we can say that our data is clean and ready to be used for analysis! Take a look at what our clean DataFrame looks like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9148c116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== GENERAL INFORMATION ==================\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7773 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Transaction ID    7773 non-null   object        \n",
      " 1   Item              7773 non-null   object        \n",
      " 2   Quantity          7773 non-null   float64       \n",
      " 3   Price Per Unit    7773 non-null   float64       \n",
      " 4   Total Spent       7773 non-null   float64       \n",
      " 5   Payment Method    7773 non-null   object        \n",
      " 6   Location          7773 non-null   object        \n",
      " 7   Transaction Date  7773 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(3), object(4)\n",
      "memory usage: 546.5+ KB\n",
      "\n",
      "========== COUNT OF MISSING (NULL) VALUES ==========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transaction ID      0\n",
       "Item                0\n",
       "Quantity            0\n",
       "Price Per Unit      0\n",
       "Total Spent         0\n",
       "Payment Method      0\n",
       "Location            0\n",
       "Transaction Date    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Technical summary: data types and non-null count\n",
    "print(\"================== GENERAL INFORMATION ==================\\n\")\n",
    "df_clean.info()\n",
    "\n",
    "# Count of missing (null) values in each column\n",
    "print(\"\\n========== COUNT OF MISSING (NULL) VALUES ==========\")\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51bb313",
   "metadata": {},
   "source": [
    "## Step 7: Save a New, Clean .csv File\n",
    "\n",
    "With the entire data cleaning process completed, we just need to save our new .csv file to be used!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ddf6a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File '../data/processed/cleaned_cafe_sales.csv' saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the clean CSV file\n",
    "final_file_name = '../data/processed/cleaned_cafe_sales.csv'\n",
    "df_clean.to_csv(final_file_name, index=False, encoding='utf-8')\n",
    "print(f\"\\nFile '{final_file_name}' saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
